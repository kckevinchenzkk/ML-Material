{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第一组']\n",
      "强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.20.20.20' '10.20.20.20' '20.20.20.20' '30.20.20.20' '40.20.20.20'\n",
      " '50.20.20.20' '60.20.20.20' '70.20.20.20' '80.20.20.20' '90.20.20.20'\n",
      " '100.20.20.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 2:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第二组']\n",
      "强度: [40 40 40 40 40 40 40 40 40 40 40 nan nan]\n",
      "变形强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.40.20.20' '10.40.20.20' '20.40.20.20' '30.40.20.20' '40.40.20.20'\n",
      " '50.40.20.20' '60.40.20.20' '70.40.20.20' '80.40.20.20' '90.40.20.20'\n",
      " '100.40.20.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 3:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第三组']\n",
      "强度: [60 60 60 60 60 60 60 60 60 60 60 nan nan]\n",
      "变形强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.60.20.20' '10.60.20.20' '20.60.20.20' '30.60.20.20' '40.60.20.20'\n",
      " '50.60.20.20' '60.60.20.20' '70.60.20.20' '80.60.20.20' '90.60.20.20'\n",
      " '100.60.20.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 4:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第四组']\n",
      "强度: [80 80 80 80 80 80 80 80 80 80 80 nan nan]\n",
      "变形强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.80.20.20' '10.80.20.20' '20.80.20.20' '30.80.20.20' '40.80.20.20'\n",
      " '50.80.20.20' '60.80.20.20' '70.80.20.20' '80.80.20.20' '90.80.20.20'\n",
      " '100.80.20.20' nan nan]\n",
      "\n",
      "\n",
      "Group 5:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第五组']\n",
      "强度: [100 100 100 100 100 100 100 100 100 100 100 nan nan]\n",
      "变形强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.100.20.20' '10.100.20.20' '20.100.20.20' '30.100.20.20' '40.100.20.20'\n",
      " '50.100.20.20' '60.100.20.20' '70.100.20.20' '80.100.20.20'\n",
      " '90.100.20.20' '100.100.20.20' nan nan]\n",
      "\n",
      "\n",
      "Group 6:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第六组']\n",
      "强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形强度: [40 40 40 40 40 40 40 40 40 40 40 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.20.40.20' '10.20.40.20' '20.20.40.20' '30.20.40.20' '40.20.40.20'\n",
      " '50.20.40.20' '60.20.40.20' '70.20.40.20' '80.20.40.20' '90.20.40.20'\n",
      " '100.20.40.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 7:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第七组']\n",
      "强度: [40 40 40 40 40 40 40 40 40 40 40 nan nan]\n",
      "变形强度: [40 40 40 40 40 40 40 40 40 40 40 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.40.40.20' '10.40.40.20' '20.40.40.20' '30.40.40.20' '40.40.40.20'\n",
      " '50.40.40.20' '60.40.40.20' '70.40.40.20' '80.40.40.20' '90.40.40.20'\n",
      " '100.40.40.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 8:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第八组']\n",
      "强度: [60 60 60 60 60 60 60 60 60 60 60 nan nan]\n",
      "变形强度: [40 40 40 40 40 40 40 40 40 40 40 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.60.40.20' '10.60.40.20' '20.60.40.20' '30.60.40.20' '40.60.40.20'\n",
      " '50.60.40.20' '60.60.40.20' '70.60.40.20' '80.60.40.20' '90.60.40.20'\n",
      " '100.60.40.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 9:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第九组']\n",
      "强度: [80 80 80 80 80 80 80 80 80 80 80 nan nan]\n",
      "变形强度: [40 40 40 40 40 40 40 40 40 40 40 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.80.40.20' '10.80.40.20' '20.80.40.20' '30.80.40.20' '40.80.40.20'\n",
      " '50.80.40.20' '60.80.40.20' '70.80.40.20' '80.80.40.20' '90.80.40.20'\n",
      " '100.80.40.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 10:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '第十组']\n",
      "强度: [100 100 100 100 100 100 100 100 100 100 100 nan nan]\n",
      "变形强度: [40 40 40 40 40 40 40 40 40 40 40 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.100.40.20' '10.100.40.20' '20.100.40.20' '30.100.40.20' '40.100.40.20'\n",
      " '50.100.40.20' '60.100.40.20' '70.100.40.20' '80.100.40.20'\n",
      " '90.100.40.20' '100.100.40.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 11:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '十一']\n",
      "强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形强度: [60 60 60 60 60 60 60 60 60 60 60 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.20.60.20' '10.20.60.20' '20.20.60.20' '30.20.60.20' '40.20.60.20'\n",
      " '50.20.60.20' '60.20.60.20' '70.20.60.20' '80.20.60.20' '90.20.60.20'\n",
      " '100.20.60.20' '文件名' nan]\n",
      "\n",
      "\n",
      "Group 12:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '十二']\n",
      "强度: [40 40 40 40 40 40 40 40 40 40 40 nan nan]\n",
      "变形强度: [60 60 60 60 60 60 60 60 60 60 60 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.40.60.20' '10.40.60.20' '20.40.60.20' '30.40.60.20' '40.40.60.20'\n",
      " '50.40.60.20' '60.40.60.20' '70.40.60.20' '80.40.60.20' '90.40.60.20'\n",
      " '100.40.60.20' nan nan]\n",
      "\n",
      "\n",
      "Group 13:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '十三']\n",
      "强度: [60 60 60 60 60 60 60 60 60 60 60 nan nan]\n",
      "变形强度: [60 60 60 60 60 60 60 60 60 60 60 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.60.60.20' '10.60.60.20' '20.60.60.20' '30.60.60.20' '40.60.60.20'\n",
      " '50.60.60.20' '60.60.60.20' '70.60.60.20' '80.60.60.20' '90.60.60.20'\n",
      " '100.60.60.20' nan nan]\n",
      "\n",
      "\n",
      "Group 14:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '十四']\n",
      "强度: [80 80 80 80 80 80 80 80 80 80 80 nan nan]\n",
      "变形强度: [60 60 60 60 60 60 60 60 60 60 60 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.80.60.20' '10.80.60.20' '20.80.60.20' '30.80.60.20' '40.80.60.20'\n",
      " '50.80.60.20' '60.80.60.20' '70.80.60.20' '80.80.60.20' '90.80.60.20'\n",
      " '100.80.60.20' nan nan]\n",
      "\n",
      "\n",
      "Group 15:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '十五']\n",
      "强度: [100 100 100 100 100 100 100 100 100 100 100 nan nan]\n",
      "变形强度: [60 60 60 60 60 60 60 60 60 60 60 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: ['0.100.60.20' '10.100.60.20' '20.100.40.20' '30.100.60.20' '40.100.60.20'\n",
      " '50.100.60.20' '60.100.60.20' '70.100.60.20' '80.100.60.20'\n",
      " '90.100.60.20' '100.100.60.20' nan nan]\n",
      "\n",
      "\n",
      "Group 16:\n",
      "弯曲强度: [0 10 20 30 40 50 60 70 80 90 100 nan '十六组']\n",
      "强度: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "变形强度: [80 80 80 80 80 80 80 80 80 80 80 nan nan]\n",
      "变形率: [20 20 20 20 20 20 20 20 20 20 20 nan nan]\n",
      "文件名: [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data from Excel\n",
    "excel_path = './Materials_data/面料库数据表.xlsx'  # Replace with actual file path\n",
    "data = pd.read_excel(excel_path, sheet_name=None, header=None)\n",
    "\n",
    "# Initialize an empty list to store each group's data\n",
    "groups = []\n",
    "\n",
    "# Iterate through the DataFrame in steps of 5 rows per group\n",
    "for sheet_name, df in data.items():\n",
    "    for i in range(0, len(df), 5):\n",
    "        if pd.isna(df.iloc[i, 13]):\n",
    "            break\n",
    "        group_data = df.iloc[i:i+5]  # Get the 5 rows for the current group\n",
    "        \n",
    "        # Extract values for each row within the group\n",
    "        bending_strength = group_data.iloc[0, 1:].values  # Skip first column which is the label\n",
    "        strength = group_data.iloc[1, 1:].values\n",
    "        deformation_strength = group_data.iloc[2, 1:].values\n",
    "        deformation_rate = group_data.iloc[3, 1:].values\n",
    "        filenames = group_data.iloc[4, 1:].values\n",
    "        \n",
    "        # Store the group data in a dictionary\n",
    "        group = {\n",
    "            \"Bending Strength\": bending_strength,\n",
    "            \"Strength\": strength,\n",
    "            \"Deformation Strength\": deformation_strength,\n",
    "            \"Deformation Rate\": deformation_rate,\n",
    "            \"Filenames\": filenames\n",
    "        }\n",
    "        groups.append(group)\n",
    "\n",
    "# Display each group's data to verify\n",
    "for idx, group in enumerate(groups, start=1):\n",
    "    print(f\"Group {idx}:\")\n",
    "    print(\"弯曲强度:\", group[\"Bending Strength\"])\n",
    "    print(\"强度:\", group[\"Strength\"])\n",
    "    print(\"变形强度:\", group[\"Deformation Strength\"])\n",
    "    print(\"变形率:\", group[\"Deformation Rate\"])\n",
    "    print(\"文件名:\", group[\"Filenames\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "def preprocess_image(image):\n",
    "    # Resize and normalize image\n",
    "    image = tf.image.resize(image, (105, 105))  # Standard size for example\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "def load_data(image_pairs, labels):\n",
    "    # Preprocess each image in pairs\n",
    "    left_images = [preprocess_image(img[0]) for img in image_pairs]\n",
    "    right_images = [preprocess_image(img[1]) for img in image_pairs]\n",
    "    return (np.array(left_images), np.array(right_images)), np.array(labels)\n",
    "\n",
    "# Example image pairs and labels (for demonstration, replace with actual data)\n",
    "# Each pair should be a tuple of two images, and labels should be 1 for similar, 0 for dissimilar\n",
    "# Assuming your_image_pairs is a list of tuples of images and your_labels is a list of 0 or 1 labels\n",
    "# For example: your_image_pairs = [(img1, img2), (img3, img4), ...]\n",
    "# your_labels = [1, 0, ...]\n",
    "\n",
    "your_image_pairs = []  # Replace with actual image pairs\n",
    "your_labels = []       # Replace with actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the Siamese Network Model\n",
    "def build_base_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, (10, 10), activation='relu', input_shape=(105, 105, 3)),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (7, 7), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (4, 4), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(256, (4, 4), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_siamese_model():\n",
    "    input_left = layers.Input(name=\"left_input\", shape=(105, 105, 3))\n",
    "    input_right = layers.Input(name=\"right_input\", shape=(105, 105, 3))\n",
    "\n",
    "    base_model = build_base_model()\n",
    "\n",
    "    output_left = base_model(input_left)\n",
    "    output_right = base_model(input_right)\n",
    "\n",
    "    # Compute L1 distance between features\n",
    "    l1_distance = tf.abs(output_left - output_right)\n",
    "    output = layers.Dense(1, activation='sigmoid')(l1_distance)\n",
    "\n",
    "    siamese_model = Model(inputs=[input_left, input_right], outputs=output)\n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compile the Model\n",
    "siamese_model = build_siamese_model()\n",
    "siamese_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Load your pairs and labels\n",
    "(image_pairs, labels) = load_data(your_image_pairs, your_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input data to be non-empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 4: Train the Model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msiamese_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_pairs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_pairs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1319\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_dataset_and_inferred_steps(\n\u001b[1;32m   1315\u001b[0m     strategy, x, steps_per_epoch, class_weight, distribute\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected input data to be non-empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input data to be non-empty."
     ]
    }
   ],
   "source": [
    "# Step 4: Train the Model\n",
    "siamese_model.fit([image_pairs[0], image_pairs[1]], labels, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Make Predictions\n",
    "def predict_similarity(model, img1, img2):\n",
    "    img1 = preprocess_image(img1)\n",
    "    img2 = preprocess_image(img2)\n",
    "    img1 = tf.expand_dims(img1, axis=0)\n",
    "    img2 = tf.expand_dims(img2, axis=0)\n",
    "    return model.predict([img1, img2])[0][0]\n",
    "\n",
    "# Example usage for prediction\n",
    "# Replace test_img1 and test_img2 with actual images you want to compare\n",
    "# test_img1, test_img2 = <image1>, <image2>\n",
    "\n",
    "# similarity_score = predict_similarity(siamese_model, test_img1, test_img2)\n",
    "# print(\"Similarity score:\", similarity_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
