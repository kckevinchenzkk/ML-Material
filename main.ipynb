{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Image Class with Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1:\n",
      "  Group: 第一组\n",
      "  Bending Strength: 0\n",
      "  Strength: 20\n",
      "  Deformation Strength: 20\n",
      "  Deformation Rate: 20\n",
      "  Filename: 0.20.20.20\n",
      "  Top Image Path: ./Materials_data/第一组/0.20.20.20-1.jpg\n",
      "  Side Image Path: ./Materials_data/第一组/0.20.20.20-2.jpg\n",
      "\n",
      "\n",
      "Image 2:\n",
      "  Group: 第一组\n",
      "  Bending Strength: 10\n",
      "  Strength: 20\n",
      "  Deformation Strength: 20\n",
      "  Deformation Rate: 20\n",
      "  Filename: 10.20.20.20\n",
      "  Top Image Path: ./Materials_data/第一组/10.20.20.20-1.jpg\n",
      "  Side Image Path: ./Materials_data/第一组/10.20.20.20-2.jpg\n",
      "\n",
      "\n",
      "Image 3:\n",
      "  Group: 第一组\n",
      "  Bending Strength: 20\n",
      "  Strength: 20\n",
      "  Deformation Strength: 20\n",
      "  Deformation Rate: 20\n",
      "  Filename: 20.20.20.20\n",
      "  Top Image Path: ./Materials_data/第一组/20.20.20.20-1.jpg\n",
      "  Side Image Path: ./Materials_data/第一组/20.20.20.20-2.jpg\n",
      "\n",
      "\n",
      "Image 4:\n",
      "  Group: 第一组\n",
      "  Bending Strength: 30\n",
      "  Strength: 20\n",
      "  Deformation Strength: 20\n",
      "  Deformation Rate: 20\n",
      "  Filename: 30.20.20.20\n",
      "  Top Image Path: ./Materials_data/第一组/30.20.20.20-1.jpg\n",
      "  Side Image Path: ./Materials_data/第一组/30.20.20.20-2.jpg\n",
      "\n",
      "\n",
      "Image 5:\n",
      "  Group: 第一组\n",
      "  Bending Strength: 40\n",
      "  Strength: 20\n",
      "  Deformation Strength: 20\n",
      "  Deformation Rate: 20\n",
      "  Filename: 40.20.20.20\n",
      "  Top Image Path: ./Materials_data/第一组/40.20.20.20-1.jpg\n",
      "  Side Image Path: ./Materials_data/第一组/40.20.20.20-2.jpg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class ImageData:\n",
    "    def __init__(self, bending_strength, strength, deformation_strength, deformation_rate, filename, group_name):\n",
    "        self.bending_strength = bending_strength\n",
    "        self.strength = strength\n",
    "        self.deformation_strength = deformation_strength\n",
    "        self.deformation_rate = deformation_rate\n",
    "        self.filename = filename\n",
    "        self.group_name = group_name\n",
    "        # Define separate paths for top and side views based on filename\n",
    "        self.top_image_path = f\"./Materials_data/{group_name}/{filename}-1.jpg\"\n",
    "        self.side_image_path = f\"./Materials_data/{group_name}/{filename}-2.jpg\"\n",
    "\n",
    "    def load_top_image(self):\n",
    "        # Load the top view image\n",
    "        image = tf.io.read_file(self.top_image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)  # Assuming JPEG format as per filenames\n",
    "        image = tf.image.resize(image, (105, 105))  # Standardize size\n",
    "        image = image / 255.0  # Normalize to [0, 1]\n",
    "        return image\n",
    "\n",
    "    def load_side_image(self):\n",
    "        # Load the side view image\n",
    "        image = tf.io.read_file(self.side_image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (105, 105))  # Standardize size\n",
    "        image = image / 255.0  # Normalize to [0, 1]\n",
    "        return image\n",
    "    \n",
    "# Load the data from Excel\n",
    "excel_path = './Materials_data/面料库数据表.xlsx'  # Replace with actual file path\n",
    "data = pd.read_excel(excel_path, sheet_name=None, header=None)\n",
    "\n",
    "# Initialize a list to store ImageData objects for each image\n",
    "images = []\n",
    "\n",
    "# Iterate through the DataFrame in steps of 5 rows per group\n",
    "for sheet_name, df in data.items():\n",
    "    for i in range(0, len(df), 5):\n",
    "        if pd.isna(df.iloc[i, 12]):\n",
    "            break\n",
    "        group_name = df.iloc[i, 12]\n",
    "        bending_strength = df.iloc[i, 1:12].values\n",
    "        strength = df.iloc[i+1, 1:12].values\n",
    "        deformation_strength = df.iloc[i+2, 1:12].values\n",
    "        deformation_rate = df.iloc[i+3, 1:12].values\n",
    "        filenames = df.iloc[i+4, 1:12].values\n",
    "        \n",
    "        # Create ImageData instances\n",
    "        for j in range(len(filenames)):\n",
    "            img_data = ImageData(\n",
    "                bending_strength[j],\n",
    "                strength[j],\n",
    "                deformation_strength[j],\n",
    "                deformation_rate[j],\n",
    "                filenames[j],\n",
    "                group_name\n",
    "            )\n",
    "            images.append(img_data)\n",
    "\n",
    "# Display processed data for verification\n",
    "for idx, img_data in enumerate(images[:5], start=1):  # Display first 5 entries for verification\n",
    "    print(f\"Image {idx}:\")\n",
    "    print(f\"  Group: {img_data.group_name}\")\n",
    "    print(f\"  Bending Strength: {img_data.bending_strength}\")\n",
    "    print(f\"  Strength: {img_data.strength}\")\n",
    "    print(f\"  Deformation Strength: {img_data.deformation_strength}\")\n",
    "    print(f\"  Deformation Rate: {img_data.deformation_rate}\")\n",
    "    print(f\"  Filename: {img_data.filename}\")\n",
    "    print(f\"  Top Image Path: {img_data.top_image_path}\")\n",
    "    print(f\"  Side Image Path: {img_data.side_image_path}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Pairs for Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_pairs(images):\n",
    "    image_pairs = []\n",
    "    labels = []\n",
    "    # Pair images within the same group (similar) and across groups (dissimilar)\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i+1, len(images)):\n",
    "            if images[i].group_name == images[j].group_name:\n",
    "                label = 1  # Similar\n",
    "            else:\n",
    "                label = 0  # Dissimilar\n",
    "            image_pairs.append((images[i], images[j]))\n",
    "            labels.append(label)\n",
    "    return image_pairs, labels\n",
    "\n",
    "image_pairs, labels = create_pairs(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess and Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 00:08:39.526199: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: ./Materials_data/第七组/30.40.40.20-2.jpg; No such file or directory\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} ./Materials_data/第七组/30.40.40.20-2.jpg; No such file or directory [Op:ReadFile]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m right_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m image_pairs:\n\u001b[0;32m---> 11\u001b[0m     img1, img2 \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     left_images\u001b[38;5;241m.\u001b[39mappend(img1)\n\u001b[1;32m     13\u001b[0m     right_images\u001b[38;5;241m.\u001b[39mappend(img2)\n",
      "Cell \u001b[0;32mIn[75], line 3\u001b[0m, in \u001b[0;36mpreprocess_image_pair\u001b[0;34m(image_pair)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image_pair\u001b[39m(image_pair):\n\u001b[1;32m      2\u001b[0m     img1 \u001b[38;5;241m=\u001b[39m image_pair[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mload_top_image()  \u001b[38;5;66;03m# Load the top view for the first image\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     img2 \u001b[38;5;241m=\u001b[39m \u001b[43mimage_pair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_side_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load the side view for the second image\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img1, img2\n",
      "Cell \u001b[0;32mIn[72], line 28\u001b[0m, in \u001b[0;36mImageData.load_side_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_side_image\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Load the side view image\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mside_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_jpeg(image, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     30\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m105\u001b[39m, \u001b[38;5;241m105\u001b[39m))  \u001b[38;5;66;03m# Standardize size\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/ops/io_ops.py:134\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(filename, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the contents of file.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m  This operation returns a tensor with the entire contents of the input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    A tensor of dtype \"string\", with the file contents.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_io_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/ops/gen_io_ops.py:583\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_file_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/ops/gen_io_ops.py:606\u001b[0m, in \u001b[0;36mread_file_eager_fallback\u001b[0;34m(filename, name, ctx)\u001b[0m\n\u001b[1;32m    604\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [filename]\n\u001b[1;32m    605\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[1;32m    609\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[1;32m    610\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadFile\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: {{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} ./Materials_data/第七组/30.40.40.20-2.jpg; No such file or directory [Op:ReadFile]"
     ]
    }
   ],
   "source": [
    "def preprocess_image_pair(image_pair):\n",
    "    img1 = image_pair[0].load_top_image()  # Load the top view for the first image\n",
    "    img2 = image_pair[1].load_side_image()  # Load the side view for the second image\n",
    "    return img1, img2\n",
    "\n",
    "# Process all image pairs\n",
    "left_images = []\n",
    "right_images = []\n",
    "\n",
    "for pair in image_pairs:\n",
    "    img1, img2 = preprocess_image_pair(pair)\n",
    "    left_images.append(img1)\n",
    "    right_images.append(img2)\n",
    "\n",
    "# Convert lists to numpy arrays for model input\n",
    "left_images = np.array(left_images)\n",
    "right_images = np.array(right_images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define and Compile the Siamese Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, (10, 10), activation='relu', input_shape=(105, 105, 3)),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (7, 7), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (4, 4), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(256, (4, 4), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_siamese_model():\n",
    "    input_left = layers.Input(name=\"left_input\", shape=(105, 105, 3))\n",
    "    input_right = layers.Input(name=\"right_input\", shape=(105, 105, 3))\n",
    "\n",
    "    base_model = build_base_model()\n",
    "\n",
    "    output_left = base_model(input_left)\n",
    "    output_right = base_model(input_right)\n",
    "\n",
    "    # Compute L1 distance between features\n",
    "    l1_distance = tf.abs(output_left - output_right)\n",
    "    output = layers.Dense(1, activation='sigmoid')(l1_distance)\n",
    "\n",
    "    siamese_model = Model(inputs=[input_left, input_right], outputs=output)\n",
    "    return siamese_model\n",
    "\n",
    "# Compile the model\n",
    "siamese_model = build_siamese_model()\n",
    "siamese_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "siamese_model.fit([left_images, right_images], labels, batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_similarity(img_data1, img_data2):\n",
    "    img1 = img_data1.load_image()\n",
    "    img2 = img_data2.load_image()\n",
    "    img1 = np.expand_dims(img1, axis=0)\n",
    "    img2 = np.expand_dims(img2, axis=0)\n",
    "    return siamese_model.predict([img1, img2])[0][0]\n",
    "\n",
    "# Example usage\n",
    "similarity_score = predict_similarity(images[0], images[1])\n",
    "print(\"Similarity score:\", similarity_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
