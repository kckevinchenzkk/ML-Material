{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Clean Data Loader for Regression"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nclass RegressionDataLoader:\n    def __init__(self, data_path='./Materials_data'):\n        self.data_path = data_path\n        self.param_scaler = MinMaxScaler()\n        \n    def extract_parameters_from_folder(self, folder_name):\n        \"\"\"Extract continuous parameters from folder name format: 1-20.20.20.20-1\"\"\"\n        try:\n            # Remove any prefix before the first number\n            parts = folder_name.split('-')\n            if len(parts) >= 2:\n                # Extract the parameter string (e.g., \"20.20.20.20\")\n                param_str = parts[1]\n                # Split into individual parameters\n                params = [float(x) for x in param_str.split('.')]\n                if len(params) == 4:\n                    return params  # [弯曲强度, 强度, 形变强度, 形变率]\n        except:\n            pass\n        return None\n    \n    def load_dual_view_images(self, folder_path):\n        \"\"\"Load top-view (-1) and side-view (-2) images from folder\"\"\"\n        top_images = []\n        side_images = []\n        \n        # Find all image files in folder\n        if not os.path.exists(folder_path):\n            return [], []\n            \n        for filename in os.listdir(folder_path):\n            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n                if filename.endswith('-1.jpg'):\n                    # Top view image\n                    img_path = os.path.join(folder_path, filename)\n                    try:\n                        img = load_img(img_path, target_size=(224, 224))\n                        img_array = img_to_array(img) / 255.0\n                        top_images.append(img_array)\n                    except:\n                        continue\n                elif filename.endswith('-2.jpg'):\n                    # Side view image\n                    img_path = os.path.join(folder_path, filename)\n                    try:\n                        img = load_img(img_path, target_size=(224, 224))\n                        img_array = img_to_array(img) / 255.0\n                        side_images.append(img_array)\n                    except:\n                        continue\n        \n        return top_images, side_images\n    \n    def load_regression_data(self):\n        \"\"\"Load all data for regression training\"\"\"\n        top_images = []\n        side_images = []\n        parameters = []\n        folder_names = []\n        \n        print(\"Loading regression data from folder structure...\")\n        \n        # Scan all folders in data path\n        for folder_name in os.listdir(self.data_path):\n            folder_path = os.path.join(self.data_path, folder_name)\n            \n            if not os.path.isdir(folder_path):\n                continue\n                \n            # Extract parameters from folder name\n            params = self.extract_parameters_from_folder(folder_name)\n            if params is None:\n                continue\n                \n            # Load images from this folder\n            folder_top_images, folder_side_images = self.load_dual_view_images(folder_path)\n            \n            # Match top and side images (assuming same count)\n            min_count = min(len(folder_top_images), len(folder_side_images))\n            \n            for i in range(min_count):\n                top_images.append(folder_top_images[i])\n                side_images.append(folder_side_images[i])\n                parameters.append(params)\n                folder_names.append(folder_name)\n                \n        # Convert to numpy arrays\n        top_images = np.array(top_images)\n        side_images = np.array(side_images)\n        parameters = np.array(parameters)\n        \n        # Normalize parameters to [0,1] range for training\n        parameters_normalized = self.param_scaler.fit_transform(parameters)\n        \n        print(f\"Loaded {len(top_images)} samples\")\n        print(f\"Parameter ranges: {np.min(parameters, axis=0)} to {np.max(parameters, axis=0)}\")\n        print(f\"Parameter names: ['弯曲强度', '强度', '形变强度', '形变率']\")\n        \n        return top_images, side_images, parameters_normalized, parameters, folder_names\n\n# Test the data loader\ndata_loader = RegressionDataLoader()\ntop_imgs, side_imgs, params_norm, params_orig, folders = data_loader.load_regression_data()\n\n# Display sample\nif len(top_imgs) > 0:\n    print(f\"\\nSample data:\")\n    print(f\"Top image shape: {top_imgs[0].shape}\")\n    print(f\"Side image shape: {side_imgs[0].shape}\")\n    print(f\"Parameters (original): {params_orig[0]}\")\n    print(f\"Parameters (normalized): {params_norm[0]}\")\n    print(f\"Folder: {folders[0]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Pairs for Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_pairs(images):\n",
    "    image_pairs = []\n",
    "    labels = []\n",
    "    # Pair images within the same group (similar) and across groups (dissimilar)\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i+1, len(images)):\n",
    "            if images[i].group_name == images[j].group_name:\n",
    "                label = 1  # Similar\n",
    "            else:\n",
    "                label = 0  # Dissimilar\n",
    "            image_pairs.append((images[i], images[j]))\n",
    "            labels.append(label)\n",
    "    return image_pairs, labels\n",
    "\n",
    "image_pairs, labels = create_pairs(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess and Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 00:08:39.526199: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: ./Materials_data/第七组/30.40.40.20-2.jpg; No such file or directory\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} ./Materials_data/第七组/30.40.40.20-2.jpg; No such file or directory [Op:ReadFile]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m right_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m image_pairs:\n\u001b[0;32m---> 11\u001b[0m     img1, img2 \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     left_images\u001b[38;5;241m.\u001b[39mappend(img1)\n\u001b[1;32m     13\u001b[0m     right_images\u001b[38;5;241m.\u001b[39mappend(img2)\n",
      "Cell \u001b[0;32mIn[75], line 3\u001b[0m, in \u001b[0;36mpreprocess_image_pair\u001b[0;34m(image_pair)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image_pair\u001b[39m(image_pair):\n\u001b[1;32m      2\u001b[0m     img1 \u001b[38;5;241m=\u001b[39m image_pair[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mload_top_image()  \u001b[38;5;66;03m# Load the top view for the first image\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     img2 \u001b[38;5;241m=\u001b[39m \u001b[43mimage_pair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_side_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load the side view for the second image\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img1, img2\n",
      "Cell \u001b[0;32mIn[72], line 28\u001b[0m, in \u001b[0;36mImageData.load_side_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_side_image\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Load the side view image\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mside_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_jpeg(image, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     30\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m105\u001b[39m, \u001b[38;5;241m105\u001b[39m))  \u001b[38;5;66;03m# Standardize size\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/ops/io_ops.py:134\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.read_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(filename, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the contents of file.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m  This operation returns a tensor with the entire contents of the input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    A tensor of dtype \"string\", with the file contents.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_io_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/ops/gen_io_ops.py:583\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_file_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/ops/gen_io_ops.py:606\u001b[0m, in \u001b[0;36mread_file_eager_fallback\u001b[0;34m(filename, name, ctx)\u001b[0m\n\u001b[1;32m    604\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [filename]\n\u001b[1;32m    605\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[1;32m    609\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[1;32m    610\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadFile\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: {{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} ./Materials_data/第七组/30.40.40.20-2.jpg; No such file or directory [Op:ReadFile]"
     ]
    }
   ],
   "source": [
    "def preprocess_image_pair(image_pair):\n",
    "    img1 = image_pair[0].load_top_image()  # Load the top view for the first image\n",
    "    img2 = image_pair[1].load_side_image()  # Load the side view for the second image\n",
    "    return img1, img2\n",
    "\n",
    "# Process all image pairs\n",
    "left_images = []\n",
    "right_images = []\n",
    "\n",
    "for pair in image_pairs:\n",
    "    img1, img2 = preprocess_image_pair(pair)\n",
    "    left_images.append(img1)\n",
    "    right_images.append(img2)\n",
    "\n",
    "# Convert lists to numpy arrays for model input\n",
    "left_images = np.array(left_images)\n",
    "right_images = np.array(right_images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define and Compile the Siamese Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, (10, 10), activation='relu', input_shape=(105, 105, 3)),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (7, 7), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (4, 4), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(256, (4, 4), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_siamese_model():\n",
    "    input_left = layers.Input(name=\"left_input\", shape=(105, 105, 3))\n",
    "    input_right = layers.Input(name=\"right_input\", shape=(105, 105, 3))\n",
    "\n",
    "    base_model = build_base_model()\n",
    "\n",
    "    output_left = base_model(input_left)\n",
    "    output_right = base_model(input_right)\n",
    "\n",
    "    # Compute L1 distance between features\n",
    "    l1_distance = tf.abs(output_left - output_right)\n",
    "    output = layers.Dense(1, activation='sigmoid')(l1_distance)\n",
    "\n",
    "    siamese_model = Model(inputs=[input_left, input_right], outputs=output)\n",
    "    return siamese_model\n",
    "\n",
    "# Compile the model\n",
    "siamese_model = build_siamese_model()\n",
    "siamese_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "siamese_model.fit([left_images, right_images], labels, batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_similarity(img_data1, img_data2):\n",
    "    img1 = img_data1.load_image()\n",
    "    img2 = img_data2.load_image()\n",
    "    img1 = np.expand_dims(img1, axis=0)\n",
    "    img2 = np.expand_dims(img2, axis=0)\n",
    "    return siamese_model.predict([img1, img2])[0][0]\n",
    "\n",
    "# Example usage\n",
    "similarity_score = predict_similarity(images[0], images[1])\n",
    "print(\"Similarity score:\", similarity_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}