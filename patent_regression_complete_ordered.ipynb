{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flexible_patent_regression_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Create flexible patent-based regression model that can handle:\n",
    "    - Top view only\n",
    "    - Side view only  \n",
    "    - Both views (dual-view)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Single image input (can be top, side, or both)\n",
    "    image_input = Input(shape=input_shape, name='image_input')\n",
    "    \n",
    "    # CNN backbone for feature extraction\n",
    "    base_cnn = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_cnn.trainable = False\n",
    "    \n",
    "    # Extract features\n",
    "    features = base_cnn(image_input)\n",
    "    features = GlobalAveragePooling2D(name='gap')(features)\n",
    "    \n",
    "    # Feature processing\n",
    "    processed = Dense(512, activation='relu', name='dense1')(features)\n",
    "    processed = BatchNormalization(name='bn1')(processed)\n",
    "    processed = Dropout(0.3, name='dropout1')(processed)\n",
    "    \n",
    "    processed = Dense(256, activation='relu', name='dense2')(processed)\n",
    "    processed = BatchNormalization(name='bn2')(processed)\n",
    "    processed = Dropout(0.3, name='dropout2')(processed)\n",
    "    \n",
    "    # Final regression output\n",
    "    parameter_predictions = Dense(4, activation='linear', name='parameter_regression')(processed)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=image_input, outputs=parameter_predictions, \n",
    "                  name='FlexiblePatentRegressionModel')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Alternative: Update the predictor class to handle flexible inputs\n",
    "class FlexiblePatentRegressionPredictor:\n",
    "    \"\"\"\n",
    "    Flexible predictor that can work with top-only, side-only, or dual-view images\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, data_path='./Materials_data'):\n",
    "        self.model_path = model_path\n",
    "        self.data_path = data_path\n",
    "        self.model = None\n",
    "        self.reference_data = None\n",
    "        self.param_scaler = None\n",
    "        \n",
    "        # Parameter names and weights from patent\n",
    "        self.param_names = ['弯曲强度', '强度', '形变强度', '形变率']\n",
    "        self.param_names_en = ['Bending_Strength', 'Strength', 'Deformation_Strength', 'Deformation_Rate']\n",
    "        self.param_weights = np.array([1.0, 0.6, 0.6, 0.3])\n",
    "        \n",
    "    def predict_with_single_image(self, image_path, view_type='auto'):\n",
    "        \"\"\"\n",
    "        Predict parameters using a single image\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image\n",
    "            view_type: 'top', 'side', or 'auto' (auto-detect from filename)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.model is None:\n",
    "            self.load_model_and_data()\n",
    "        \n",
    "        # Auto-detect view type from filename if not specified\n",
    "        if view_type == 'auto':\n",
    "            if '-1.' in image_path or 'top' in image_path.lower():\n",
    "                view_type = 'top'\n",
    "            elif '-2.' in image_path or 'side' in image_path.lower():\n",
    "                view_type = 'side'\n",
    "            else:\n",
    "                view_type = 'unknown'\n",
    "        \n",
    "        # Preprocess image\n",
    "        img = self.preprocess_single_image(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        # Make prediction - use the same image for both inputs in dual-view model\n",
    "        img_input = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        try:\n",
    "            # If using the original dual-view model, provide same image for both inputs\n",
    "            predictions_normalized = self.model.predict([img_input, img_input], verbose=0)\n",
    "            \n",
    "            # Denormalize predictions\n",
    "            if self.param_scaler is not None:\n",
    "                predictions_original = self.param_scaler.inverse_transform(predictions_normalized)\n",
    "            else:\n",
    "                predictions_original = predictions_normalized\n",
    "            \n",
    "            return {\n",
    "                'predicted_parameters_original': predictions_original[0],\n",
    "                'predicted_parameters_normalized': predictions_normalized[0],\n",
    "                'parameter_names': self.param_names,\n",
    "                'parameter_names_en': self.param_names_en,\n",
    "                'image_path': image_path,\n",
    "                'view_type': view_type,\n",
    "                'note': f'Prediction based on {view_type} view image'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def preprocess_single_image(self, image_path):\n",
    "        \"\"\"Preprocess a single image\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(image_path):\n",
    "                return None\n",
    "            \n",
    "            img = load_img(image_path, target_size=(224, 224), color_mode='rgb')\n",
    "            img_array = img_to_array(img) / 255.0\n",
    "            return img_array\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error preprocessing image {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_model_and_data(self):\n",
    "        \"\"\"Load the trained model and reference data\"\"\"\n",
    "        print(\"Loading model and reference data...\")\n",
    "        \n",
    "        try:\n",
    "            # Load model with custom objects\n",
    "            parameter_weights = self.param_weights\n",
    "            custom_objects = {\n",
    "                'weighted_mse': parameter_weighted_mse_loss(parameter_weights),\n",
    "                'weighted_mae': parameter_weighted_mae_loss(parameter_weights)\n",
    "            }\n",
    "            \n",
    "            self.model = tf.keras.models.load_model(self.model_path, custom_objects=custom_objects)\n",
    "            print(f\"Model loaded from {self.model_path}\")\n",
    "            \n",
    "            # Load reference data for similarity comparison\n",
    "            data_loader = PatentRegressionDataLoader(self.data_path, normalize_params=True)\n",
    "            top_images, side_images, parameter_values, folder_names, image_paths = data_loader.load_regression_data()\n",
    "            \n",
    "            self.param_scaler = data_loader.param_scaler\n",
    "            \n",
    "            self.reference_data = {\n",
    "                'parameters_normalized': parameter_values,\n",
    "                'folder_names': folder_names,\n",
    "                'image_paths': image_paths\n",
    "            }\n",
    "            \n",
    "            if self.param_scaler is not None:\n",
    "                self.reference_data['parameters_original'] = self.param_scaler.inverse_transform(parameter_values)\n",
    "            else:\n",
    "                self.reference_data['parameters_original'] = parameter_values\n",
    "            \n",
    "            print(f\"Reference dataset loaded: {len(folder_names)} samples\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model or data: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patent-Based Material Parameter Regression\n",
    "Complete implementation for continuous parameter prediction from dual-view images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Concatenate, Dropout, \n",
    "                                   GlobalAveragePooling2D, BatchNormalization,\n",
    "                                   Lambda, Add, Multiply)\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import imghdr\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentRegressionDataLoader:\n",
    "    \"\"\"\n",
    "    Regression data loader following patent specifications:\n",
    "    - Predicts continuous parameter values from dual-view images\n",
    "    - Target: [弯曲强度, 强度, 形变强度, 形变率] (continuous values 0-100)\n",
    "    - Patent methodology: Replace physical testing with AI image analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, image_size=(224, 224), normalize_params=True):\n",
    "        self.data_path = data_path\n",
    "        self.image_size = image_size\n",
    "        self.normalize_params = normalize_params\n",
    "        \n",
    "        # Parameter importance weights from patent findings\n",
    "        # 弯曲强度(最显著), 强度(较显著), 形变强度(较显著), 形变率(不显著)\n",
    "        self.parameter_weights = np.array([1.0, 0.6, 0.6, 0.3], dtype=np.float32)\n",
    "        \n",
    "        # Parameter names for reference\n",
    "        self.param_names = ['弯曲强度', '强度', '形变强度', '形变率']\n",
    "        self.param_names_en = ['Bending_Strength', 'Strength', 'Deformation_Strength', 'Deformation_Rate']\n",
    "        \n",
    "        # Parameter scalers for normalization\n",
    "        self.param_scaler = None\n",
    "        \n",
    "    def extract_parameters_from_folder(self, folder_name):\n",
    "        \"\"\"\n",
    "        Extract continuous physical parameters from folder name for regression\n",
    "        Format: \"1-20.20.20.20-1\" -> [20.0, 20.0, 20.0, 20.0]\n",
    "        Returns raw parameter values (not discretized)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            parts = folder_name.split('-')\n",
    "            if len(parts) >= 2:\n",
    "                param_str = parts[1]  # \"20.20.20.20\"\n",
    "                params = [float(x) for x in param_str.split('.')]\n",
    "                if len(params) >= 4:\n",
    "                    # Validate parameter ranges and return raw values\n",
    "                    validated_params = []\n",
    "                    for i, param in enumerate(params[:4]):\n",
    "                        # Ensure parameters are in valid range [0, 100]\n",
    "                        validated_params.append(max(0.0, min(100.0, param)))\n",
    "                    return validated_params\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting parameters from {folder_name}: {e}\")\n",
    "        \n",
    "        # Default parameters if extraction fails\n",
    "        return [0.0, 20.0, 20.0, 20.0]\n",
    "    \n",
    "    def load_and_preprocess_image(self, image_path):\n",
    "        \"\"\"Load and preprocess image according to patent specifications\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(image_path):\n",
    "                return None\n",
    "                \n",
    "            # Check if valid image\n",
    "            if imghdr.what(image_path) not in ['jpeg', 'jpg', 'png']:\n",
    "                return None\n",
    "                \n",
    "            # Load image as RGB (patent specifies color capture)\n",
    "            img = load_img(image_path, target_size=self.image_size, color_mode='rgb')\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize to [0,1]\n",
    "            return img_array\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_regression_data(self):\n",
    "        \"\"\"\n",
    "        Load dual-view images with continuous parameter targets for regression\n",
    "        Returns: top_images, side_images, parameter_values, folder_names\n",
    "        \"\"\"\n",
    "        top_images = []\n",
    "        side_images = []\n",
    "        parameter_values = []\n",
    "        folder_names = []\n",
    "        image_paths = []\n",
    "        \n",
    "        print(\"Loading patent-based regression data...\")\n",
    "        print(\"Target: Continuous parameter prediction [弯曲强度, 强度, 形变强度, 形变率]\")\n",
    "        \n",
    "        for folder in sorted(os.listdir(self.data_path)):\n",
    "            folder_path = os.path.join(self.data_path, folder)\n",
    "            \n",
    "            if not os.path.isdir(folder_path):\n",
    "                continue\n",
    "                \n",
    "            # Extract continuous physical parameters from folder name\n",
    "            params = self.extract_parameters_from_folder(folder)\n",
    "            \n",
    "            # Find image pairs (top-view and side-view)\n",
    "            files = os.listdir(folder_path)\n",
    "            image_pairs = {}\n",
    "            \n",
    "            for file in files:\n",
    "                if file.endswith('.jpg') or file.endswith('.png'):\n",
    "                    if '-1.' in file:  # Top view\n",
    "                        base_name = file.replace('-1.', '.')\n",
    "                        if base_name not in image_pairs:\n",
    "                            image_pairs[base_name] = {}\n",
    "                        image_pairs[base_name]['top'] = file\n",
    "                    elif '-2.' in file:  # Side view\n",
    "                        base_name = file.replace('-2.', '.')\n",
    "                        if base_name not in image_pairs:\n",
    "                            image_pairs[base_name] = {}\n",
    "                        image_pairs[base_name]['side'] = file\n",
    "            \n",
    "            # Load valid pairs for regression training\n",
    "            for base_name, pair in image_pairs.items():\n",
    "                if 'top' in pair and 'side' in pair:\n",
    "                    top_path = os.path.join(folder_path, pair['top'])\n",
    "                    side_path = os.path.join(folder_path, pair['side'])\n",
    "                    \n",
    "                    top_img = self.load_and_preprocess_image(top_path)\n",
    "                    side_img = self.load_and_preprocess_image(side_path)\n",
    "                    \n",
    "                    if top_img is not None and side_img is not None:\n",
    "                        top_images.append(top_img)\n",
    "                        side_images.append(side_img)\n",
    "                        parameter_values.append(params)\n",
    "                        folder_names.append(folder)\n",
    "                        image_paths.append((top_path, side_path))\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        top_images = np.array(top_images)\n",
    "        side_images = np.array(side_images)\n",
    "        parameter_values = np.array(parameter_values, dtype=np.float32)\n",
    "        \n",
    "        print(f\"Loaded {len(top_images)} image pairs for regression\")\n",
    "        print(f\"Parameter shape: {parameter_values.shape}\")\n",
    "        \n",
    "        # Store data statistics for analysis\n",
    "        self._store_regression_statistics(parameter_values, folder_names)\n",
    "        \n",
    "        # Normalize parameters if requested\n",
    "        if self.normalize_params:\n",
    "            parameter_values = self._normalize_parameters(parameter_values)\n",
    "            print(\"Parameters normalized to [0,1] range\")\n",
    "        \n",
    "        return top_images, side_images, parameter_values, folder_names, image_paths\n",
    "    \n",
    "    def _normalize_parameters(self, parameter_values):\n",
    "        \"\"\"Normalize parameters to [0,1] range for better training stability\"\"\"\n",
    "        if self.param_scaler is None:\n",
    "            # Use MinMaxScaler to normalize to [0,1] range\n",
    "            self.param_scaler = MinMaxScaler()\n",
    "            normalized_params = self.param_scaler.fit_transform(parameter_values)\n",
    "        else:\n",
    "            normalized_params = self.param_scaler.transform(parameter_values)\n",
    "        \n",
    "        return normalized_params.astype(np.float32)\n",
    "    \n",
    "    def denormalize_parameters(self, normalized_params):\n",
    "        \"\"\"Convert normalized parameters back to original scale\"\"\"\n",
    "        if self.param_scaler is None:\n",
    "            print(\"Warning: No scaler available for denormalization\")\n",
    "            return normalized_params\n",
    "        \n",
    "        return self.param_scaler.inverse_transform(normalized_params)\n",
    "    \n",
    "    def _store_regression_statistics(self, parameter_values, folder_names):\n",
    "        \"\"\"Store regression data statistics for analysis\"\"\"\n",
    "        self._data_stats = {\n",
    "            'total_samples': len(parameter_values),\n",
    "            'unique_folders': len(set(folder_names)),\n",
    "            'parameter_statistics': {}\n",
    "        }\n",
    "        \n",
    "        print(\"\\nRegression Target Statistics:\")\n",
    "        for i, (name_zh, name_en) in enumerate(zip(self.param_names, self.param_names_en)):\n",
    "            param_vals = parameter_values[:, i]\n",
    "            stats = {\n",
    "                'mean': np.mean(param_vals),\n",
    "                'std': np.std(param_vals),\n",
    "                'min': np.min(param_vals),\n",
    "                'max': np.max(param_vals),\n",
    "                'median': np.median(param_vals)\n",
    "            }\n",
    "            self._data_stats['parameter_statistics'][name_en] = stats\n",
    "            \n",
    "            print(f\"  {name_zh} ({name_en}):\")\n",
    "            print(f\"    Range: [{stats['min']:.1f}, {stats['max']:.1f}]\")\n",
    "            print(f\"    Mean±Std: {stats['mean']:.1f}±{stats['std']:.1f}\")\n",
    "        \n",
    "        # Check parameter distribution\n",
    "        print(f\"\\nParameter Distribution Analysis:\")\n",
    "        for i, name in enumerate(self.param_names_en):\n",
    "            unique_vals = len(np.unique(parameter_values[:, i]))\n",
    "            print(f\"  {name}: {unique_vals} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patent_regression_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Create patent-based regression model for continuous parameter prediction\n",
    "    \n",
    "    Architecture:\n",
    "    - Dual-view CNN feature extraction (ResNet50 backbone)\n",
    "    - Multi-modal feature fusion\n",
    "    - Regression head for 4 continuous parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dual-view image inputs\n",
    "    top_view = Input(shape=input_shape, name='top_view')\n",
    "    side_view = Input(shape=input_shape, name='side_view')\n",
    "    \n",
    "    # Shared CNN backbone for feature extraction\n",
    "    base_cnn = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_cnn.trainable = False  # Start with frozen weights for transfer learning\n",
    "    \n",
    "    # Extract features from both views\n",
    "    top_features = base_cnn(top_view)\n",
    "    side_features = base_cnn(side_view)\n",
    "    \n",
    "    # Global Average Pooling\n",
    "    top_features = GlobalAveragePooling2D(name='top_gap')(top_features)\n",
    "    side_features = GlobalAveragePooling2D(name='side_gap')(side_features)\n",
    "    \n",
    "    # View-specific processing\n",
    "    top_processed = Dense(512, activation='relu', name='top_dense')(top_features)\n",
    "    top_processed = BatchNormalization(name='top_bn')(top_processed)\n",
    "    top_processed = Dropout(0.3, name='top_dropout')(top_processed)\n",
    "    \n",
    "    side_processed = Dense(512, activation='relu', name='side_dense')(side_features)\n",
    "    side_processed = BatchNormalization(name='side_bn')(side_processed)\n",
    "    side_processed = Dropout(0.3, name='side_dropout')(side_processed)\n",
    "    \n",
    "    # Multi-view fusion with attention\n",
    "    combined_features = Concatenate(name='view_fusion')([top_processed, side_processed])\n",
    "    \n",
    "    # Attention mechanism for view importance\n",
    "    attention_weights = Dense(1024, activation='softmax', name='view_attention')(combined_features)\n",
    "    attended_features = Multiply(name='attended_features')([combined_features, attention_weights])\n",
    "    \n",
    "    # Regression head with parameter-specific branches\n",
    "    fusion_dense = Dense(512, activation='relu', name='fusion_dense1')(attended_features)\n",
    "    fusion_dense = BatchNormalization(name='fusion_bn1')(fusion_dense)\n",
    "    fusion_dense = Dropout(0.4, name='fusion_dropout1')(fusion_dense)\n",
    "    \n",
    "    fusion_dense = Dense(256, activation='relu', name='fusion_dense2')(fusion_dense)\n",
    "    fusion_dense = BatchNormalization(name='fusion_bn2')(fusion_dense)\n",
    "    fusion_dense = Dropout(0.3, name='fusion_dropout2')(fusion_dense)\n",
    "    \n",
    "    # Final regression output - 4 continuous parameters\n",
    "    # Using linear activation for regression (no bounds imposed here)\n",
    "    parameter_predictions = Dense(4, activation='linear', name='parameter_regression')(fusion_dense)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=[top_view, side_view], outputs=parameter_predictions, \n",
    "                  name='PatentRegressionModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_weighted_mse_loss(parameter_weights):\n",
    "    \"\"\"\n",
    "    Create parameter-weighted MSE loss based on patent importance findings\n",
    "    \n",
    "    Args:\n",
    "        parameter_weights: Array of importance weights [弯曲强度, 强度, 形变强度, 形变率]\n",
    "    \"\"\"\n",
    "    def weighted_mse(y_true, y_pred):\n",
    "        # Compute squared errors for each parameter\n",
    "        squared_errors = tf.square(y_true - y_pred)\n",
    "        \n",
    "        # Apply importance weights from patent\n",
    "        weighted_errors = squared_errors * tf.constant(parameter_weights, dtype=tf.float32)\n",
    "        \n",
    "        # Return mean weighted error\n",
    "        return tf.reduce_mean(weighted_errors)\n",
    "    \n",
    "    return weighted_mse\n",
    "\n",
    "def parameter_weighted_mae_loss(parameter_weights):\n",
    "    \"\"\"\n",
    "    Create parameter-weighted MAE loss for more robust training\n",
    "    \"\"\"\n",
    "    def weighted_mae(y_true, y_pred):\n",
    "        # Compute absolute errors for each parameter\n",
    "        abs_errors = tf.abs(y_true - y_pred)\n",
    "        \n",
    "        # Apply importance weights from patent\n",
    "        weighted_errors = abs_errors * tf.constant(parameter_weights, dtype=tf.float32)\n",
    "        \n",
    "        # Return mean weighted error\n",
    "        return tf.reduce_mean(weighted_errors)\n",
    "    \n",
    "    return weighted_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_callbacks():\n",
    "    \"\"\"Create callbacks for regression training\"\"\"\n",
    "    return [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=25,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'best_patent_regression_model.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def evaluate_regression_model(model, X_test, y_test, param_scaler=None):\n",
    "    \"\"\"Evaluate regression model with comprehensive metrics\"\"\"\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Denormalize if scaler is provided\n",
    "    if param_scaler is not None:\n",
    "        y_test_orig = param_scaler.inverse_transform(y_test)\n",
    "        y_pred_orig = param_scaler.inverse_transform(y_pred)\n",
    "    else:\n",
    "        y_test_orig = y_test\n",
    "        y_pred_orig = y_pred\n",
    "    \n",
    "    print(\"\\nRegression Evaluation Results:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Parameter names\n",
    "    param_names = ['Bending_Strength', 'Strength', 'Deformation_Strength', 'Deformation_Rate']\n",
    "    param_names_zh = ['弯曲强度', '强度', '形变强度', '形变率']\n",
    "    \n",
    "    # Overall metrics\n",
    "    overall_mse = mean_squared_error(y_test, y_pred)\n",
    "    overall_mae = mean_absolute_error(y_test, y_pred)\n",
    "    overall_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Overall Metrics (Normalized):\")\n",
    "    print(f\"  MSE: {overall_mse:.4f}\")\n",
    "    print(f\"  MAE: {overall_mae:.4f}\")\n",
    "    print(f\"  R²: {overall_r2:.4f}\")\n",
    "    \n",
    "    # Per-parameter metrics\n",
    "    print(f\"\\nPer-Parameter Metrics (Original Scale):\")\n",
    "    for i, (name_en, name_zh) in enumerate(zip(param_names, param_names_zh)):\n",
    "        mse = mean_squared_error(y_test_orig[:, i], y_pred_orig[:, i])\n",
    "        mae = mean_absolute_error(y_test_orig[:, i], y_pred_orig[:, i])\n",
    "        r2 = r2_score(y_test_orig[:, i], y_pred_orig[:, i])\n",
    "        \n",
    "        print(f\"  {name_zh} ({name_en}):\")\n",
    "        print(f\"    MSE: {mse:.4f}\")\n",
    "        print(f\"    MAE: {mae:.4f}\")\n",
    "        print(f\"    R²: {r2:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'overall_mse': overall_mse,\n",
    "        'overall_mae': overall_mae,\n",
    "        'overall_r2': overall_r2,\n",
    "        'predictions': y_pred,\n",
    "        'predictions_original': y_pred_orig,\n",
    "        'true_values': y_test,\n",
    "        'true_values_original': y_test_orig\n",
    "    }\n",
    "\n",
    "def plot_regression_results(results, save_path='regression_results.png'):\n",
    "    \"\"\"Plot regression prediction results\"\"\"\n",
    "    \n",
    "    y_true_orig = results['true_values_original']\n",
    "    y_pred_orig = results['predictions_original']\n",
    "    \n",
    "    param_names = ['Bending Strength', 'Strength', 'Deformation Strength', 'Deformation Rate']\n",
    "    param_names_zh = ['弯曲强度', '强度', '形变强度', '形变率']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, (ax, name_en, name_zh) in enumerate(zip(axes, param_names, param_names_zh)):\n",
    "        # Scatter plot of true vs predicted\n",
    "        ax.scatter(y_true_orig[:, i], y_pred_orig[:, i], alpha=0.6, color=f'C{i}')\n",
    "        \n",
    "        # Perfect prediction line\n",
    "        min_val = min(y_true_orig[:, i].min(), y_pred_orig[:, i].min())\n",
    "        max_val = max(y_true_orig[:, i].max(), y_pred_orig[:, i].max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Prediction')\n",
    "        \n",
    "        # Calculate R²\n",
    "        r2 = r2_score(y_true_orig[:, i], y_pred_orig[:, i])\n",
    "        mae = mean_absolute_error(y_true_orig[:, i], y_pred_orig[:, i])\n",
    "        \n",
    "        ax.set_xlabel(f'True {name_en}')\n",
    "        ax.set_ylabel(f'Predicted {name_en}')\n",
    "        ax.set_title(f'{name_zh}\\nR² = {r2:.3f}, MAE = {mae:.2f}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Regression results plotted and saved to {save_path}\")\n",
    "\n",
    "def plot_training_history(history, fine_tune_history=None):\n",
    "    \"\"\"Plot training history for regression model\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    \n",
    "    if fine_tune_history:\n",
    "        epochs_offset = len(history.history['loss'])\n",
    "        ax1.plot(range(epochs_offset, epochs_offset + len(fine_tune_history.history['loss'])),\n",
    "                fine_tune_history.history['loss'], label='Fine-tune Training', linestyle='--', color='blue')\n",
    "        ax1.plot(range(epochs_offset, epochs_offset + len(fine_tune_history.history['val_loss'])),\n",
    "                fine_tune_history.history['val_loss'], label='Fine-tune Validation', linestyle='--', color='orange')\n",
    "    \n",
    "    ax1.set_title('Model Loss (Parameter-Weighted MSE)')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot MAE\n",
    "    ax2.plot(history.history['mae'], label='Training MAE', color='green')\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE', color='red')\n",
    "    \n",
    "    if fine_tune_history:\n",
    "        epochs_offset = len(history.history['mae'])\n",
    "        ax2.plot(range(epochs_offset, epochs_offset + len(fine_tune_history.history['mae'])),\n",
    "                fine_tune_history.history['mae'], label='Fine-tune Training MAE', linestyle='--', color='green')\n",
    "        ax2.plot(range(epochs_offset, epochs_offset + len(fine_tune_history.history['val_mae'])),\n",
    "                fine_tune_history.history['val_mae'], label='Fine-tune Validation MAE', linestyle='--', color='red')\n",
    "    \n",
    "    ax2.set_title('Model MAE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Mean Absolute Error')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('regression_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_flexible_patent_regression_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Create flexible patent-based regression model that can handle:\n",
    "    - Top view only\n",
    "    - Side view only  \n",
    "    - Both views (dual-view)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Single image input (can be top, side, or both)\n",
    "    image_input = Input(shape=input_shape, name='image_input')\n",
    "    \n",
    "    # CNN backbone for feature extraction\n",
    "    base_cnn = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_cnn.trainable = False\n",
    "    \n",
    "    # Extract features\n",
    "    features = base_cnn(image_input)\n",
    "    features = GlobalAveragePooling2D(name='gap')(features)\n",
    "    \n",
    "    # Feature processing\n",
    "    processed = Dense(512, activation='relu', name='dense1')(features)\n",
    "    processed = BatchNormalization(name='bn1')(processed)\n",
    "    processed = Dropout(0.3, name='dropout1')(processed)\n",
    "    \n",
    "    processed = Dense(256, activation='relu', name='dense2')(processed)\n",
    "    processed = BatchNormalization(name='bn2')(processed)\n",
    "    processed = Dropout(0.3, name='dropout2')(processed)\n",
    "    \n",
    "    # Final regression output\n",
    "    parameter_predictions = Dense(4, activation='linear', name='parameter_regression')(processed)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=image_input, outputs=parameter_predictions, \n",
    "                  name='FlexiblePatentRegressionModel')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Alternative: Update the predictor class to handle flexible inputs\n",
    "class FlexiblePatentRegressionPredictor:\n",
    "    \"\"\"\n",
    "    Flexible predictor that can work with top-only, side-only, or dual-view images\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, data_path='./Materials_data'):\n",
    "        self.model_path = model_path\n",
    "        self.data_path = data_path\n",
    "        self.model = None\n",
    "        self.reference_data = None\n",
    "        self.param_scaler = None\n",
    "        \n",
    "        # Parameter names and weights from patent\n",
    "        self.param_names = ['弯曲强度', '强度', '形变强度', '形变率']\n",
    "        self.param_names_en = ['Bending_Strength', 'Strength', 'Deformation_Strength', 'Deformation_Rate']\n",
    "        self.param_weights = np.array([1.0, 0.6, 0.6, 0.3])\n",
    "        \n",
    "    def predict_with_single_image(self, image_path, view_type='auto'):\n",
    "        \"\"\"\n",
    "        Predict parameters using a single image\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image\n",
    "            view_type: 'top', 'side', or 'auto' (auto-detect from filename)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.model is None:\n",
    "            self.load_model_and_data()\n",
    "        \n",
    "        # Auto-detect view type from filename if not specified\n",
    "        if view_type == 'auto':\n",
    "            if '-1.' in image_path or 'top' in image_path.lower():\n",
    "                view_type = 'top'\n",
    "            elif '-2.' in image_path or 'side' in image_path.lower():\n",
    "                view_type = 'side'\n",
    "            else:\n",
    "                view_type = 'unknown'\n",
    "        \n",
    "        # Preprocess image\n",
    "        img = self.preprocess_single_image(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        # Make prediction - use the same image for both inputs in dual-view model\n",
    "        img_input = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        try:\n",
    "            # If using the original dual-view model, provide same image for both inputs\n",
    "            predictions_normalized = self.model.predict([img_input, img_input], verbose=0)\n",
    "            \n",
    "            # Denormalize predictions\n",
    "            if self.param_scaler is not None:\n",
    "                predictions_original = self.param_scaler.inverse_transform(predictions_normalized)\n",
    "            else:\n",
    "                predictions_original = predictions_normalized\n",
    "            \n",
    "            return {\n",
    "                'predicted_parameters_original': predictions_original[0],\n",
    "                'predicted_parameters_normalized': predictions_normalized[0],\n",
    "                'parameter_names': self.param_names,\n",
    "                'parameter_names_en': self.param_names_en,\n",
    "                'image_path': image_path,\n",
    "                'view_type': view_type,\n",
    "                'note': f'Prediction based on {view_type} view image'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def predict_material_parameters(self, top_image_path, side_image_path):\n",
    "        \"\"\"\n",
    "        Predict parameters using dual-view images (compatible with original predictor)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            self.load_model_and_data()\n",
    "        \n",
    "        # Preprocess both images\n",
    "        top_img = self.preprocess_single_image(top_image_path)\n",
    "        side_img = self.preprocess_single_image(side_image_path)\n",
    "        \n",
    "        if top_img is None or side_img is None:\n",
    "            return None\n",
    "        \n",
    "        # Prepare input arrays\n",
    "        top_input = np.expand_dims(top_img, axis=0)\n",
    "        side_input = np.expand_dims(side_img, axis=0)\n",
    "        \n",
    "        try:\n",
    "            # Use dual-view inputs\n",
    "            predictions_normalized = self.model.predict([top_input, side_input], verbose=0)\n",
    "            \n",
    "            # Denormalize predictions\n",
    "            if self.param_scaler is not None:\n",
    "                predictions_original = self.param_scaler.inverse_transform(predictions_normalized)\n",
    "            else:\n",
    "                predictions_original = predictions_normalized\n",
    "            \n",
    "            return {\n",
    "                'predicted_parameters_original': predictions_original[0],\n",
    "                'predicted_parameters_normalized': predictions_normalized[0],\n",
    "                'parameter_names': self.param_names,\n",
    "                'parameter_names_en': self.param_names_en,\n",
    "                'top_image_path': top_image_path,\n",
    "                'side_image_path': side_image_path\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during dual-view prediction: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def preprocess_single_image(self, image_path):\n",
    "        \"\"\"Preprocess a single image\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(image_path):\n",
    "                return None\n",
    "            \n",
    "            img = load_img(image_path, target_size=(224, 224), color_mode='rgb')\n",
    "            img_array = img_to_array(img) / 255.0\n",
    "            return img_array\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error preprocessing image {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_model_and_data(self):\n",
    "        \"\"\"Load the trained model and reference data\"\"\"\n",
    "        print(\"Loading model and reference data...\")\n",
    "        \n",
    "        try:\n",
    "            # Load model with custom objects\n",
    "            parameter_weights = self.param_weights\n",
    "            custom_objects = {\n",
    "                'weighted_mse': parameter_weighted_mse_loss(parameter_weights),\n",
    "                'weighted_mae': parameter_weighted_mae_loss(parameter_weights)\n",
    "            }\n",
    "            \n",
    "            self.model = tf.keras.models.load_model(self.model_path, custom_objects=custom_objects)\n",
    "            print(f\"Model loaded from {self.model_path}\")\n",
    "            \n",
    "            # Load reference data for similarity comparison\n",
    "            data_loader = PatentRegressionDataLoader(self.data_path, normalize_params=True)\n",
    "            top_images, side_images, parameter_values, folder_names, image_paths = data_loader.load_regression_data()\n",
    "            \n",
    "            self.param_scaler = data_loader.param_scaler\n",
    "            \n",
    "            self.reference_data = {\n",
    "                'parameters_normalized': parameter_values,\n",
    "                'folder_names': folder_names,\n",
    "                'image_paths': image_paths\n",
    "            }\n",
    "            \n",
    "            if self.param_scaler is not None:\n",
    "                self.reference_data['parameters_original'] = self.param_scaler.inverse_transform(parameter_values)\n",
    "            else:\n",
    "                self.reference_data['parameters_original'] = parameter_values\n",
    "            \n",
    "            print(f\"Reference dataset loaded: {len(folder_names)} samples\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model or data: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_patent_regression_model():\n",
    "    \"\"\"Main training function for patent-based regression\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"Patent-Based Material Parameter Regression Training\")\n",
    "    print(\"Target: Continuous parameter prediction from dual-view images\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Load regression data\n",
    "    print(\"\\nStep 1: Loading patent-based regression data...\")\n",
    "    data_loader = PatentRegressionDataLoader('./Materials_data', normalize_params=True)\n",
    "    \n",
    "    top_images, side_images, parameter_values, folder_names, image_paths = data_loader.load_regression_data()\n",
    "    \n",
    "    if len(top_images) == 0:\n",
    "        print(\"ERROR: No valid regression data found!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded {len(top_images)} image pairs for regression training\")\n",
    "    print(f\"Parameter shape: {parameter_values.shape}\")\n",
    "    \n",
    "    # 2. Split data for regression\n",
    "    print(\"\\nStep 2: Creating train/validation split...\")\n",
    "    indices = np.arange(len(top_images))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Split data\n",
    "    top_train, top_val = top_images[train_idx], top_images[val_idx]\n",
    "    side_train, side_val = side_images[train_idx], side_images[val_idx]\n",
    "    param_train, param_val = parameter_values[train_idx], parameter_values[val_idx]\n",
    "    \n",
    "    print(f\"Training set: {len(top_train)} samples\")\n",
    "    print(f\"Validation set: {len(top_val)} samples\")\n",
    "    \n",
    "    # 3. Create regression model\n",
    "    print(\"\\nStep 3: Creating patent-based regression model...\")\n",
    "    model = create_patent_regression_model(input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Display model summary\n",
    "    print(\"Model Architecture Summary:\")\n",
    "    print(f\"Total Parameters: {model.count_params():,}\")\n",
    "    print(f\"Input: Dual-view images + continuous parameter prediction\")\n",
    "    print(f\"Output: 4 continuous parameters [弯曲强度, 强度, 形变强度, 形变率]\")\n",
    "    \n",
    "    # 4. Compile with parameter-weighted loss\n",
    "    print(\"\\nStep 4: Compiling model with parameter-weighted loss...\")\n",
    "    \n",
    "    # Parameter importance weights from patent\n",
    "    parameter_weights = np.array([1.0, 0.6, 0.6, 0.3], dtype=np.float32)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss=parameter_weighted_mse_loss(parameter_weights),\n",
    "        metrics=[\n",
    "            'mae',\n",
    "            parameter_weighted_mae_loss(parameter_weights)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 5. Setup callbacks\n",
    "    print(\"\\nStep 5: Setting up training callbacks...\")\n",
    "    callbacks = create_regression_callbacks()\n",
    "    \n",
    "    # 6. Train model\n",
    "    print(\"\\nStep 6: Starting regression training...\")\n",
    "    print(\"Training with:\")\n",
    "    print(\"- Dual-view image inputs (top + side)\")\n",
    "    print(\"- Parameter-weighted MSE loss\")\n",
    "    print(\"- Patent-based importance weighting\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        [top_train, side_train],\n",
    "        param_train,\n",
    "        validation_data=([top_val, side_val], param_val),\n",
    "        batch_size=16,\n",
    "        epochs=100,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 7. Evaluate model\n",
    "    print(\"\\nStep 7: Evaluating regression model...\")\n",
    "    results = evaluate_regression_model(\n",
    "        model, \n",
    "        [top_val, side_val], \n",
    "        param_val,\n",
    "        param_scaler=data_loader.param_scaler\n",
    "    )\n",
    "    \n",
    "    # 8. Fine-tuning phase\n",
    "    print(\"\\nStep 8: Fine-tuning with unfrozen CNN layers...\")\n",
    "    \n",
    "    # Unfreeze ResNet50 layers for fine-tuning\n",
    "    for layer in model.layers:\n",
    "        if 'resnet50' in layer.name:\n",
    "            layer.trainable = True\n",
    "            # Freeze early layers, unfreeze later ones\n",
    "            for sublayer in layer.layers[:-30]:\n",
    "                sublayer.trainable = False\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),\n",
    "        loss=parameter_weighted_mse_loss(parameter_weights),\n",
    "        metrics=['mae', parameter_weighted_mae_loss(parameter_weights)]\n",
    "    )\n",
    "    \n",
    "    # Fine-tune\n",
    "    fine_tune_history = model.fit(\n",
    "        [top_train, side_train],\n",
    "        param_train,\n",
    "        validation_data=([top_val, side_val], param_val),\n",
    "        batch_size=8,\n",
    "        epochs=30,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 9. Final evaluation\n",
    "    print(\"\\nStep 9: Final evaluation after fine-tuning...\")\n",
    "    final_results = evaluate_regression_model(\n",
    "        model,\n",
    "        [top_val, side_val], \n",
    "        param_val,\n",
    "        param_scaler=data_loader.param_scaler\n",
    "    )\n",
    "    \n",
    "    # 10. Save final model\n",
    "    model.save('patent_regression_model_final.h5')\n",
    "    print(\"Model saved as 'patent_regression_model_final.h5'\")\n",
    "    \n",
    "    # 11. Plot results\n",
    "    print(\"\\nStep 10: Plotting regression results...\")\n",
    "    plot_regression_results(final_results)\n",
    "    \n",
    "    # 12. Plot training history\n",
    "    plot_training_history(history, fine_tune_history)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Regression training completed successfully!\")\n",
    "    print(\"Files created:\")\n",
    "    print(\"- best_patent_regression_model.h5 (best model during training)\")\n",
    "    print(\"- patent_regression_model_final.h5 (final fine-tuned model)\")\n",
    "    print(\"- regression_results.png (prediction scatter plots)\")\n",
    "    print(\"- regression_training_history.png (training curves)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return model, history, fine_tune_history, final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference with ALL images in testing folder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Initialize flexible predictor for single images\n",
    "flexible_predictor = FlexiblePatentRegressionPredictor('patent_regression_model_final.h5')\n",
    "\n",
    "# Check testing folder\n",
    "testing_folder = './testing'\n",
    "if not os.path.exists(testing_folder):\n",
    "    print(f\"Testing folder '{testing_folder}' does not exist.\")\n",
    "    print(\"Please create the folder and add your test images.\")\n",
    "else:\n",
    "    # Find all image files in testing folder\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
    "    all_images = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        all_images.extend(glob.glob(os.path.join(testing_folder, ext)))\n",
    "    \n",
    "    if not all_images:\n",
    "        print(f\"No image files found in '{testing_folder}' folder.\")\n",
    "        print(\"Supported formats: .jpg, .jpeg, .png\")\n",
    "    else:\n",
    "        print(f\"Found {len(all_images)} test images in '{testing_folder}' folder:\")\n",
    "        for img in all_images:\n",
    "            print(f\"  {os.path.basename(img)}\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*80)\n",
    "        print(\"TESTING ALL IMAGES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Test each image individually\n",
    "        for i, image_path in enumerate(all_images, 1):\n",
    "            image_name = os.path.basename(image_path)\n",
    "            \n",
    "            print(f\"\\\\n[{i}/{len(all_images)}] Testing: {image_name}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Predict using single image\n",
    "            prediction_result = flexible_predictor.predict_with_single_image(image_path)\n",
    "            \n",
    "            if prediction_result is not None:\n",
    "                print(f\"View type detected: {prediction_result['view_type']}\")\n",
    "                print(f\"Note: {prediction_result['note']}\")\n",
    "                \n",
    "                print(\"\\\\nPredicted Parameters:\")\n",
    "                for j, name in enumerate(flexible_predictor.param_names):\n",
    "                    value = prediction_result['predicted_parameters_original'][j]\n",
    "                    print(f\"  {name}: {value:.2f}\")\n",
    "                    \n",
    "            else:\n",
    "                print(f\"❌ Error: Could not make prediction for {image_name}\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*80)\n",
    "        print(\"CHECKING FOR DUAL-VIEW PAIRS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Look for dual-view pairs (top + side)\n",
    "        dual_pairs = []\n",
    "        image_dict = {}\n",
    "        \n",
    "        # Group images by base name\n",
    "        for img_path in all_images:\n",
    "            img_name = os.path.basename(img_path)\n",
    "            \n",
    "            # Try to identify pairs based on naming patterns\n",
    "            if '-1.' in img_name:  # Top view\n",
    "                base_name = img_name.replace('-1.', '.')\n",
    "                if base_name not in image_dict:\n",
    "                    image_dict[base_name] = {}\n",
    "                image_dict[base_name]['top'] = img_path\n",
    "            elif '-2.' in img_name:  # Side view\n",
    "                base_name = img_name.replace('-2.', '.')\n",
    "                if base_name not in image_dict:\n",
    "                    image_dict[base_name] = {}\n",
    "                image_dict[base_name]['side'] = img_path\n",
    "            elif 'top' in img_name.lower():\n",
    "                base_name = img_name.lower().replace('top', '').replace('_', '').replace('-', '')\n",
    "                if base_name not in image_dict:\n",
    "                    image_dict[base_name] = {}\n",
    "                image_dict[base_name]['top'] = img_path\n",
    "            elif 'side' in img_name.lower():\n",
    "                base_name = img_name.lower().replace('side', '').replace('_', '').replace('-', '')\n",
    "                if base_name not in image_dict:\n",
    "                    image_dict[base_name] = {}\n",
    "                image_dict[base_name]['side'] = img_path\n",
    "        \n",
    "        # Find complete pairs\n",
    "        for base_name, pair_dict in image_dict.items():\n",
    "            if 'top' in pair_dict and 'side' in pair_dict:\n",
    "                dual_pairs.append((pair_dict['top'], pair_dict['side']))\n",
    "        \n",
    "        if dual_pairs:\n",
    "            print(f\"\\\\nFound {len(dual_pairs)} dual-view pairs:\")\n",
    "            \n",
    "            # Initialize original dual-view predictor for better dual-view handling\n",
    "            dual_predictor = PatentRegressionPredictor('patent_regression_model_final.h5')\n",
    "            dual_predictor.load_model_and_data()\n",
    "            \n",
    "            for i, (top_path, side_path) in enumerate(dual_pairs, 1):\n",
    "                top_name = os.path.basename(top_path)\n",
    "                side_name = os.path.basename(side_path)\n",
    "                \n",
    "                print(f\"\\\\n[Pair {i}] Top: {top_name} + Side: {side_name}\")\n",
    "                print(\"-\" * 60)\n",
    "                \n",
    "                # Predict using dual-view\n",
    "                dual_result = dual_predictor.predict_material_parameters(top_path, side_path)\n",
    "                \n",
    "                if dual_result is not None:\n",
    "                    print(\"Dual-view Predicted Parameters:\")\n",
    "                    for j, name in enumerate(dual_predictor.param_names):\n",
    "                        value = dual_result['predicted_parameters_original'][j]\n",
    "                        print(f\"  {name}: {value:.2f}\")\n",
    "                    \n",
    "                    print(\"\\\\n✅ Dual-view prediction (higher accuracy expected)\")\n",
    "                else:\n",
    "                    print(f\"❌ Error: Could not make dual-view prediction\")\n",
    "        else:\n",
    "            print(\"\\\\nNo dual-view pairs found.\")\n",
    "            print(\"Tip: Name your images with patterns like:\")\n",
    "            print(\"  - material1-1.jpg (top) + material1-2.jpg (side)\")\n",
    "            print(\"  - sample_top.jpg + sample_side.jpg\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*80)\n",
    "        print(\"TESTING COMPLETED\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Total images tested: {len(all_images)}\")\n",
    "        print(f\"Dual-view pairs found: {len(dual_pairs)}\")\n",
    "        print(\"\\\\nNote: Single-view predictions may be less accurate than dual-view pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and reference data...\n",
      "Model loaded from patent_regression_model_final.h5\n",
      "Loading patent-based regression data...\n",
      "Target: Continuous parameter prediction [弯曲强度, 强度, 形变强度, 形变率]\n",
      "Loaded 150 image pairs for regression\n",
      "Parameter shape: (150, 4)\n",
      "\n",
      "Regression Target Statistics:\n",
      "  弯曲强度 (Bending_Strength):\n",
      "    Range: [0.0, 100.0]\n",
      "    Mean±Std: 50.8±31.6\n",
      "  强度 (Strength):\n",
      "    Range: [20.0, 100.0]\n",
      "    Mean±Std: 63.6±27.0\n",
      "  形变强度 (Deformation_Strength):\n",
      "    Range: [20.0, 60.0]\n",
      "    Mean±Std: 41.3±15.9\n",
      "  形变率 (Deformation_Rate):\n",
      "    Range: [20.0, 100.0]\n",
      "    Mean±Std: 20.5±6.5\n",
      "\n",
      "Parameter Distribution Analysis:\n",
      "  Bending_Strength: 11 unique values\n",
      "  Strength: 5 unique values\n",
      "  Deformation_Strength: 3 unique values\n",
      "  Deformation_Rate: 2 unique values\n",
      "Parameters normalized to [0,1] range\n",
      "Reference dataset loaded: 150 samples\n",
      "No test images found. Please ensure you have at least one of:\n",
      "  ./testing/sample_top.jpg\n",
      "  ./testing/sample_side.jpg\n",
      "\\nFiles found in ./testing folder:\n",
      "  1-1.png\n",
      "  2-1.png\n",
      "\\nUpdate the paths above to match your actual test image filenames.\n",
      "\\nCould not make predictions. Please check your test images.\n"
     ]
    }
   ],
   "source": [
    "# Test inference with trained model using test images\n",
    "predictor = FlexiblePatentRegressionPredictor('patent_regression_model_final.h5')\n",
    "\n",
    "# Load model and reference data\n",
    "predictor.load_model_and_data()\n",
    "\n",
    "# Use test images from /testing folder\n",
    "test_top_path = './testing/sample_top.jpg'  # Replace with actual filename\n",
    "test_side_path = './testing/sample_side.jpg'  # Replace with actual filename\n",
    "\n",
    "# Check what images are available\n",
    "import os\n",
    "has_top = os.path.exists(test_top_path)\n",
    "has_side = os.path.exists(test_side_path)\n",
    "\n",
    "if has_top and has_side:\n",
    "    # Both images available - normal dual-view prediction\n",
    "    print(f\"Testing with dual-view images:\")\n",
    "    print(f\"  Top view: {test_top_path}\")\n",
    "    print(f\"  Side view: {test_side_path}\")\n",
    "    \n",
    "    prediction_result = predictor.predict_material_parameters(test_top_path, test_side_path)\n",
    "    \n",
    "elif has_top and not has_side:\n",
    "    # Only top view available - use top image for both views\n",
    "    print(f\"Only top view available: {test_top_path}\")\n",
    "    print(f\"Using top view for both inputs (dual-view model limitation)\")\n",
    "    \n",
    "    prediction_result = predictor.predict_material_parameters(test_top_path, test_top_path)\n",
    "    \n",
    "elif has_side and not has_top:\n",
    "    # Only side view available - use side image for both views\n",
    "    print(f\"Only side view available: {test_side_path}\")\n",
    "    print(f\"Using side view for both inputs (dual-view model limitation)\")\n",
    "    \n",
    "    prediction_result = predictor.predict_material_parameters(test_side_path, test_side_path)\n",
    "    \n",
    "else:\n",
    "    # No test images found\n",
    "    print(\"No test images found. Please ensure you have at least one of:\")\n",
    "    print(\"  ./testing/sample_top.jpg\")\n",
    "    print(\"  ./testing/sample_side.jpg\")\n",
    "    \n",
    "    # List available files in testing folder if it exists\n",
    "    if os.path.exists('./testing'):\n",
    "        print(\"\\\\nFiles found in ./testing folder:\")\n",
    "        for file in os.listdir('./testing'):\n",
    "            if file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                print(f\"  {file}\")\n",
    "        print(\"\\\\nUpdate the paths above to match your actual test image filenames.\")\n",
    "    else:\n",
    "        print(\"\\\\nNote: ./testing folder does not exist.\")\n",
    "    \n",
    "    prediction_result = None\n",
    "\n",
    "# Display results if prediction was successful\n",
    "if prediction_result is not None:\n",
    "    print(\"\\\\nPredicted Parameters:\")\n",
    "    for i, name in enumerate(predictor.param_names):\n",
    "        print(f\"  {name}: {prediction_result['predicted_parameters_original'][i]:.2f}\")\n",
    "    \n",
    "    # Find similar materials\n",
    "    similarity_results = predictor.find_similar_materials(\n",
    "        prediction_result['top_image_path'], \n",
    "        prediction_result['side_image_path'], \n",
    "        top_k=3\n",
    "    )\n",
    "    print(\"\\\\nTop 3 Similar Materials:\")\n",
    "    for material in similarity_results['similar_materials']:\n",
    "        print(f\"  {material['rank']}. {material['material_id']} (similarity: {material['similarity_score']:.4f})\")\n",
    "        print(f\"      Reference parameters: {material['reference_parameters']}\")\n",
    "        print(f\"      Parameter differences: {material['parameter_differences']}\")\n",
    "        \n",
    "    if not has_side or not has_top:\n",
    "        print(\"\\\\nNote: Results may be less accurate since the model was trained on dual-view images.\")\n",
    "else:\n",
    "    print(\"\\\\nCould not make predictions. Please check your test images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Patent-Based Material Parameter Regression Training\n",
      "Target: Continuous parameter prediction from dual-view images\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading patent-based regression data...\n",
      "Loading patent-based regression data...\n",
      "Target: Continuous parameter prediction [弯曲强度, 强度, 形变强度, 形变率]\n",
      "Loaded 150 image pairs for regression\n",
      "Parameter shape: (150, 4)\n",
      "\n",
      "Regression Target Statistics:\n",
      "  弯曲强度 (Bending_Strength):\n",
      "    Range: [0.0, 100.0]\n",
      "    Mean±Std: 50.8±31.6\n",
      "  强度 (Strength):\n",
      "    Range: [20.0, 100.0]\n",
      "    Mean±Std: 63.6±27.0\n",
      "  形变强度 (Deformation_Strength):\n",
      "    Range: [20.0, 60.0]\n",
      "    Mean±Std: 41.3±15.9\n",
      "  形变率 (Deformation_Rate):\n",
      "    Range: [20.0, 100.0]\n",
      "    Mean±Std: 20.5±6.5\n",
      "\n",
      "Parameter Distribution Analysis:\n",
      "  Bending_Strength: 11 unique values\n",
      "  Strength: 5 unique values\n",
      "  Deformation_Strength: 3 unique values\n",
      "  Deformation_Rate: 2 unique values\n",
      "Parameters normalized to [0,1] range\n",
      "Loaded 150 image pairs for regression training\n",
      "Parameter shape: (150, 4)\n",
      "\n",
      "Step 2: Creating train/validation split...\n",
      "Training set: 120 samples\n",
      "Validation set: 30 samples\n",
      "\n",
      "Step 3: Creating patent-based regression model...\n",
      "Model Architecture Summary:\n",
      "Total Parameters: 27,399,812\n",
      "Input: Dual-view images + continuous parameter prediction\n",
      "Output: 4 continuous parameters [弯曲强度, 强度, 形变强度, 形变率]\n",
      "\n",
      "Step 4: Compiling model with parameter-weighted loss...\n",
      "\n",
      "Step 5: Setting up training callbacks...\n",
      "\n",
      "Step 6: Starting regression training...\n",
      "Training with:\n",
      "- Dual-view image inputs (top + side)\n",
      "- Parameter-weighted MSE loss\n",
      "- Patent-based importance weighting\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2243 - mae: 0.4581 - weighted_mae: 0.3129\n",
      "Epoch 1: val_loss improved from inf to 0.21505, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 5s 231ms/step - loss: 0.2243 - mae: 0.4581 - weighted_mae: 0.3129 - val_loss: 0.2150 - val_mae: 0.3941 - val_weighted_mae: 0.2840 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.2099 - mae: 0.4374 - weighted_mae: 0.3026\n",
      "Epoch 2: val_loss improved from 0.21505 to 0.21046, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.2102 - mae: 0.4373 - weighted_mae: 0.3014 - val_loss: 0.2105 - val_mae: 0.3902 - val_weighted_mae: 0.2807 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.2064 - mae: 0.4292 - weighted_mae: 0.2980\n",
      "Epoch 3: val_loss improved from 0.21046 to 0.20584, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.2030 - mae: 0.4269 - weighted_mae: 0.2942 - val_loss: 0.2058 - val_mae: 0.3863 - val_weighted_mae: 0.2774 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1955 - mae: 0.4227 - weighted_mae: 0.2910\n",
      "Epoch 4: val_loss improved from 0.20584 to 0.20136, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.1932 - mae: 0.4193 - weighted_mae: 0.2891 - val_loss: 0.2014 - val_mae: 0.3825 - val_weighted_mae: 0.2741 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1913 - mae: 0.4168 - weighted_mae: 0.2877\n",
      "Epoch 5: val_loss improved from 0.20136 to 0.19693, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.1918 - mae: 0.4170 - weighted_mae: 0.2893 - val_loss: 0.1969 - val_mae: 0.3786 - val_weighted_mae: 0.2707 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1846 - mae: 0.4089 - weighted_mae: 0.2849\n",
      "Epoch 6: val_loss improved from 0.19693 to 0.19258, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.1809 - mae: 0.4041 - weighted_mae: 0.2770 - val_loss: 0.1926 - val_mae: 0.3748 - val_weighted_mae: 0.2674 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1791 - mae: 0.4016 - weighted_mae: 0.2792\n",
      "Epoch 7: val_loss improved from 0.19258 to 0.18845, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.1768 - mae: 0.3959 - weighted_mae: 0.2693 - val_loss: 0.1885 - val_mae: 0.3708 - val_weighted_mae: 0.2642 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1704 - mae: 0.3906 - weighted_mae: 0.2709\n",
      "Epoch 8: val_loss improved from 0.18845 to 0.18452, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.1699 - mae: 0.3898 - weighted_mae: 0.2684 - val_loss: 0.1845 - val_mae: 0.3671 - val_weighted_mae: 0.2611 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1590 - mae: 0.3781 - weighted_mae: 0.2607\n",
      "Epoch 9: val_loss improved from 0.18452 to 0.18066, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.1618 - mae: 0.3830 - weighted_mae: 0.2672 - val_loss: 0.1807 - val_mae: 0.3633 - val_weighted_mae: 0.2580 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1589 - mae: 0.3803 - weighted_mae: 0.2614\n",
      "Epoch 10: val_loss improved from 0.18066 to 0.17680, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.1603 - mae: 0.3820 - weighted_mae: 0.2630 - val_loss: 0.1768 - val_mae: 0.3599 - val_weighted_mae: 0.2552 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1545 - mae: 0.3753 - weighted_mae: 0.2575\n",
      "Epoch 11: val_loss improved from 0.17680 to 0.17318, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.1505 - mae: 0.3698 - weighted_mae: 0.2495 - val_loss: 0.1732 - val_mae: 0.3565 - val_weighted_mae: 0.2526 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1469 - mae: 0.3626 - weighted_mae: 0.2478\n",
      "Epoch 12: val_loss improved from 0.17318 to 0.16952, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.1482 - mae: 0.3642 - weighted_mae: 0.2518 - val_loss: 0.1695 - val_mae: 0.3529 - val_weighted_mae: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1454 - mae: 0.3573 - weighted_mae: 0.2459\n",
      "Epoch 13: val_loss improved from 0.16952 to 0.16568, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.1453 - mae: 0.3579 - weighted_mae: 0.2469 - val_loss: 0.1657 - val_mae: 0.3491 - val_weighted_mae: 0.2470 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1385 - mae: 0.3545 - weighted_mae: 0.2423\n",
      "Epoch 14: val_loss improved from 0.16568 to 0.16183, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.1416 - mae: 0.3580 - weighted_mae: 0.2488 - val_loss: 0.1618 - val_mae: 0.3452 - val_weighted_mae: 0.2440 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1399 - mae: 0.3527 - weighted_mae: 0.2410\n",
      "Epoch 15: val_loss improved from 0.16183 to 0.15802, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.1395 - mae: 0.3516 - weighted_mae: 0.2406 - val_loss: 0.1580 - val_mae: 0.3412 - val_weighted_mae: 0.2410 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1331 - mae: 0.3404 - weighted_mae: 0.2323\n",
      "Epoch 16: val_loss improved from 0.15802 to 0.15433, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.1363 - mae: 0.3455 - weighted_mae: 0.2387 - val_loss: 0.1543 - val_mae: 0.3374 - val_weighted_mae: 0.2380 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1267 - mae: 0.3330 - weighted_mae: 0.2269\n",
      "Epoch 17: val_loss improved from 0.15433 to 0.15091, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.1292 - mae: 0.3366 - weighted_mae: 0.2331 - val_loss: 0.1509 - val_mae: 0.3335 - val_weighted_mae: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1259 - mae: 0.3343 - weighted_mae: 0.2265\n",
      "Epoch 18: val_loss improved from 0.15091 to 0.14759, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.1244 - mae: 0.3322 - weighted_mae: 0.2232 - val_loss: 0.1476 - val_mae: 0.3298 - val_weighted_mae: 0.2323 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1213 - mae: 0.3259 - weighted_mae: 0.2223\n",
      "Epoch 19: val_loss improved from 0.14759 to 0.14419, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.1212 - mae: 0.3244 - weighted_mae: 0.2183 - val_loss: 0.1442 - val_mae: 0.3260 - val_weighted_mae: 0.2294 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1213 - mae: 0.3260 - weighted_mae: 0.2195\n",
      "Epoch 20: val_loss improved from 0.14419 to 0.14081, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.1218 - mae: 0.3259 - weighted_mae: 0.2210 - val_loss: 0.1408 - val_mae: 0.3223 - val_weighted_mae: 0.2267 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1129 - mae: 0.3138 - weighted_mae: 0.2119\n",
      "Epoch 21: val_loss improved from 0.14081 to 0.13751, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.1145 - mae: 0.3161 - weighted_mae: 0.2141 - val_loss: 0.1375 - val_mae: 0.3187 - val_weighted_mae: 0.2241 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1105 - mae: 0.3070 - weighted_mae: 0.2083\n",
      "Epoch 22: val_loss improved from 0.13751 to 0.13439, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.1094 - mae: 0.3044 - weighted_mae: 0.2035 - val_loss: 0.1344 - val_mae: 0.3153 - val_weighted_mae: 0.2216 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1062 - mae: 0.3077 - weighted_mae: 0.2061\n",
      "Epoch 23: val_loss improved from 0.13439 to 0.13125, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.1085 - mae: 0.3111 - weighted_mae: 0.2105 - val_loss: 0.1312 - val_mae: 0.3119 - val_weighted_mae: 0.2190 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0996 - mae: 0.2930 - weighted_mae: 0.1970\n",
      "Epoch 24: val_loss improved from 0.13125 to 0.12804, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0990 - mae: 0.2923 - weighted_mae: 0.1958 - val_loss: 0.1280 - val_mae: 0.3082 - val_weighted_mae: 0.2163 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1024 - mae: 0.3001 - weighted_mae: 0.1996\n",
      "Epoch 25: val_loss improved from 0.12804 to 0.12493, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.1013 - mae: 0.2990 - weighted_mae: 0.1963 - val_loss: 0.1249 - val_mae: 0.3046 - val_weighted_mae: 0.2135 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0973 - mae: 0.2888 - weighted_mae: 0.1930\n",
      "Epoch 26: val_loss improved from 0.12493 to 0.12199, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0978 - mae: 0.2893 - weighted_mae: 0.1931 - val_loss: 0.1220 - val_mae: 0.3008 - val_weighted_mae: 0.2108 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.1001 - mae: 0.2915 - weighted_mae: 0.1952\n",
      "Epoch 27: val_loss improved from 0.12199 to 0.11889, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0972 - mae: 0.2870 - weighted_mae: 0.1884 - val_loss: 0.1189 - val_mae: 0.2969 - val_weighted_mae: 0.2079 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0873 - mae: 0.2734 - weighted_mae: 0.1820\n",
      "Epoch 28: val_loss improved from 0.11889 to 0.11608, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0899 - mae: 0.2784 - weighted_mae: 0.1882 - val_loss: 0.1161 - val_mae: 0.2931 - val_weighted_mae: 0.2051 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0890 - mae: 0.2769 - weighted_mae: 0.1843\n",
      "Epoch 29: val_loss improved from 0.11608 to 0.11330, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0873 - mae: 0.2736 - weighted_mae: 0.1786 - val_loss: 0.1133 - val_mae: 0.2891 - val_weighted_mae: 0.2022 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0836 - mae: 0.2703 - weighted_mae: 0.1784\n",
      "Epoch 30: val_loss improved from 0.11330 to 0.11090, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0832 - mae: 0.2694 - weighted_mae: 0.1783 - val_loss: 0.1109 - val_mae: 0.2863 - val_weighted_mae: 0.2003 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0845 - mae: 0.2685 - weighted_mae: 0.1769\n",
      "Epoch 31: val_loss improved from 0.11090 to 0.10834, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0836 - mae: 0.2677 - weighted_mae: 0.1752 - val_loss: 0.1083 - val_mae: 0.2844 - val_weighted_mae: 0.1989 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0790 - mae: 0.2588 - weighted_mae: 0.1696\n",
      "Epoch 32: val_loss improved from 0.10834 to 0.10569, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0770 - mae: 0.2554 - weighted_mae: 0.1657 - val_loss: 0.1057 - val_mae: 0.2825 - val_weighted_mae: 0.1976 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0797 - mae: 0.2628 - weighted_mae: 0.1734\n",
      "Epoch 33: val_loss improved from 0.10569 to 0.10341, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0789 - mae: 0.2617 - weighted_mae: 0.1717 - val_loss: 0.1034 - val_mae: 0.2807 - val_weighted_mae: 0.1963 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0750 - mae: 0.2547 - weighted_mae: 0.1661\n",
      "Epoch 34: val_loss improved from 0.10341 to 0.10112, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0747 - mae: 0.2541 - weighted_mae: 0.1656 - val_loss: 0.1011 - val_mae: 0.2788 - val_weighted_mae: 0.1950 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0721 - mae: 0.2470 - weighted_mae: 0.1624\n",
      "Epoch 35: val_loss improved from 0.10112 to 0.09888, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0728 - mae: 0.2479 - weighted_mae: 0.1633 - val_loss: 0.0989 - val_mae: 0.2772 - val_weighted_mae: 0.1938 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0704 - mae: 0.2436 - weighted_mae: 0.1605\n",
      "Epoch 36: val_loss improved from 0.09888 to 0.09673, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0703 - mae: 0.2429 - weighted_mae: 0.1589 - val_loss: 0.0967 - val_mae: 0.2755 - val_weighted_mae: 0.1925 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0623 - mae: 0.2261 - weighted_mae: 0.1478\n",
      "Epoch 37: val_loss improved from 0.09673 to 0.09500, saving model to best_patent_regression_model.h5\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0635 - mae: 0.2284 - weighted_mae: 0.1498 - val_loss: 0.0950 - val_mae: 0.2741 - val_weighted_mae: 0.1915 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0654 - mae: 0.2317 - weighted_mae: 0.1521"
     ]
    }
   ],
   "source": [
    "# Run the complete training pipeline\n",
    "model, history, fine_tune_history, results = train_patent_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and reference data...\n",
      "Model loaded from patent_regression_model_final.h5\n",
      "Loading patent-based regression data...\n",
      "Target: Continuous parameter prediction [弯曲强度, 强度, 形变强度, 形变率]\n",
      "Loaded 150 image pairs for regression\n",
      "Parameter shape: (150, 4)\n",
      "\n",
      "Regression Target Statistics:\n",
      "  弯曲强度 (Bending_Strength):\n",
      "    Range: [0.0, 100.0]\n",
      "    Mean±Std: 50.8±31.6\n",
      "  强度 (Strength):\n",
      "    Range: [20.0, 100.0]\n",
      "    Mean±Std: 63.6±27.0\n",
      "  形变强度 (Deformation_Strength):\n",
      "    Range: [20.0, 60.0]\n",
      "    Mean±Std: 41.3±15.9\n",
      "  形变率 (Deformation_Rate):\n",
      "    Range: [20.0, 100.0]\n",
      "    Mean±Std: 20.5±6.5\n",
      "\n",
      "Parameter Distribution Analysis:\n",
      "  Bending_Strength: 11 unique values\n",
      "  Strength: 5 unique values\n",
      "  Deformation_Strength: 3 unique values\n",
      "  Deformation_Rate: 2 unique values\n",
      "Parameters normalized to [0,1] range\n",
      "Reference dataset loaded: 150 samples\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FlexiblePatentRegressionPredictor' object has no attribute 'predict_material_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m test_top_path, test_side_path \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mreference_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_paths\u001b[39m\u001b[38;5;124m'\u001b[39m][sample_idx]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Predict parameters\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m prediction_result \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_material_parameters\u001b[49m(test_top_path, test_side_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(predictor\u001b[38;5;241m.\u001b[39mparam_names):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FlexiblePatentRegressionPredictor' object has no attribute 'predict_material_parameters'"
     ]
    }
   ],
   "source": [
    "# Test inference with trained model\n",
    "predictor = FlexiblePatentRegressionPredictor('patent_regression_model_final.h5')\n",
    "\n",
    "# Example: Use a sample from the dataset\n",
    "predictor.load_model_and_data()\n",
    "sample_idx = 0\n",
    "test_top_path, test_side_path = predictor.reference_data['image_paths'][sample_idx]\n",
    "\n",
    "# Predict parameters\n",
    "prediction_result = predictor.predict_material_parameters(test_top_path, test_side_path)\n",
    "print(\"Predicted Parameters:\")\n",
    "for i, name in enumerate(predictor.param_names):\n",
    "    print(f\"  {name}: {prediction_result['predicted_parameters_original'][i]:.2f}\")\n",
    "\n",
    "# Find similar materials\n",
    "similarity_results = predictor.find_similar_materials(test_top_path, test_side_path, top_k=3)\n",
    "print(\"\\nTop 3 Similar Materials:\")\n",
    "for material in similarity_results['similar_materials']:\n",
    "    print(f\"  {material['rank']}. {material['material_id']} (similarity: {material['similarity_score']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
